{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cdbfb4",
   "metadata": {},
   "source": [
    "# Import iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5830313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "# import modules\n",
    "#---------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from neuralNetwork.perceptron import perceptron \n",
    "\n",
    "#----------------\n",
    "# Iris Dataset\n",
    "#----------------\n",
    "\n",
    "data = load_iris()\n",
    "X_org = data.data\n",
    "y_org = data.target\n",
    "print('Shape of X: ', X_org.shape)\n",
    "print('Shape of y: ', y_org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_org, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 4\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_4_5_1.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_4_5_1.npy\", nn.g_best_value_iter) # cost during the training\n",
    "        np.save(\"avgBest_113_100_100_4_5_1.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_4_5_1.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d473481",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_4_5_1.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd16301",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594499cd",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (3) with MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "embedding = MDS(n_components=3) #, metric=False)\n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc33724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 3\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_3_5_1_mds.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_3_5_1_mds.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_3_5_1_mds.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_3_5_1_mds.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_3_5_1_mds.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc234",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (3) with MDS no metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "embedding = MDS(n_components=3, metric=False) \n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 3\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_3_5_1_mdsm.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_3_5_1_mdsm.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_3_5_1_mdsm.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_3_5_1_mdsm.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The global best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a308ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_3_5_1_mdsm.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2126f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5412ca",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (2) with MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "embedding = MDS(n_components=2)#, metric=False) 10\n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0313f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 2\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_2_5_1_mds.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_2_1_mds.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_2_5_1_mds.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_2_5_1_mds.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The global best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23296008",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_2_5_1_mds.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training',cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cfac6",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (1) with MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "embedding = MDS(n_components=1)#, metric=False) 10\n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 1\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_1_5_1_mds.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_1_5_1_mds.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_1_5_1_mds.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_1_5_1_mds.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec480ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_1_5_1_mds.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e433a",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (3) with TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a75996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_embedded, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 3\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_3_5_1_tsne.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_3_5_1_tsne.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_3_5_1_tsne.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_3_5_1_tsne.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ea502",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_3_5_1_tsne.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86496cb5",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (2) with TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ',X_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_embedded, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70454d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 2\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_2_5_1_tsne.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_2_5_1_tsne.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_2_5_1_tsne.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_2_5_1_tsne.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6623420",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_2_5_1_tsne.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3cd26",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (1) with TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ea1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=1, learning_rate='auto', init='random').fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ',X_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_embedded, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 1\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_1_5_1_tsne.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_1_5_1_tsne.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_1_5_1_tsne.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_1_5_1_tsne.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The global best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_1_5_1_tsne.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1232e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43532f05",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (3) with Isomap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "embedding = Isomap(n_components=3, n_neighbors=100)\n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94658333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09182ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 3\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_3_5_1_isomap.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_3_5_1_isomap.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_3_5_1_isomap.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_3_5_1_isomap.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_3_5_1_isomap.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14137967",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (2) with Isomap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "embedding = Isomap(n_components=2, n_neighbors=100)\n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 2\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_2_5_1_isomap.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_2_5_1_isomap.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_2_5_1_isomap.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_2_5_1_isomap.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb426d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_2_5_1_isomap.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6d106",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (1) with Isomap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f5ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "embedding = Isomap(n_components=1, n_neighbors=100)\n",
    "X_transformed = embedding.fit_transform(X_org)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f299a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 1\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_1_5_1_isomap.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_1_5_1_isomap.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_1_5_1_isomap.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_1_5_1_isomap.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_1_5_1_isomap.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54bbacf",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (3) with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "from sklearn.decomposition import PCA\n",
    "embedding = PCA(n_components=3)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3086ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 3\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_3_5_1_pca.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_3_5_1_pca.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_3_5_1_pca.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_3_5_1_pca.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a28c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_3_5_1_pca.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e12153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e5244",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (2) with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "from sklearn.decomposition import PCA\n",
    "embedding = PCA(n_components=2)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49575836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 2\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_2_5_1_pca.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_2_5_1_pca.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_2_5_1_pca.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_2_5_1_pca.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de34196",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_2_5_1_pca.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfbb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44ddb9",
   "metadata": {},
   "source": [
    "# Reduce the dimention of the iris dataset (2) with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "from sklearn.decomposition import PCA\n",
    "embedding = PCA(n_components=1)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "\n",
    "X_sample = 105\n",
    "X_input = 1\n",
    "X_class = 3\n",
    "beta = 1.13 #1.13\n",
    "n_particulas = 100\n",
    "max_iter = 100\n",
    "n_training = 10\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train_bal, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"gBest_113_100_100_1_5_1_pca.npy\", gBest[i])\n",
    "        np.save(\"gBestIter_113_100_100_1_5_1_pca.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"avgBest_113_100_100_1_5_1_pca.npy\", nn.avg_best_value)\n",
    "        np.save(\"stdBest_113_100_100_1_5_1_pca.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))        \n",
    "#print(np.load(\"gBestIter_113_100_10000_150_5_1.npy\"))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gBest_aux = np.load(\"gBest_113_100_100_1_5_1_pca.npy\")\n",
    "y_test_pred = np.argmax(nn.forward(X_test, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_test, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(nn.forward(X_train, gBest_aux), axis=1)\n",
    "cost_test = mean_squared_error(y_train, y_test_pred)\n",
    "print ('Test prediction cost with training: ', cost_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qpso-env)",
   "language": "python",
   "name": "qpso-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
