{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction dimensions for iris dataset using MDS, Isomp, t-SNE, and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "# import modules\n",
    "#---------------\n",
    "\n",
    "import numpy as np\n",
    "import joblib as jb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.preprocessing import StandardScaler # for PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (569, 30)\n",
      "Shape of y:  (569,)\n"
     ]
    }
   ],
   "source": [
    "#----------------\n",
    "# Iris Dataset\n",
    "#----------------\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_org = data.data\n",
    "y_org = data.target\n",
    "print('Shape of X: ', X_org.shape)\n",
    "print('Shape of y: ', y_org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data (0,1)\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_org)\n",
    "X_org = t.transform(X_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particulas = 100\n",
    "max_iter = 1000\n",
    "n_training = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "\n",
    "embedding = PCA(n_components=25)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")\n",
    "\n",
    "X_sample = len(X_train_bal)\n",
    "X_input = len(X_train_bal[1])\n",
    "X_class = len(np.unique(y_train_bal))\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    print('Training ', i+1, '...')\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(X_input * 3, ), activation='tanh', solver='lbfgs', max_iter=max_iter, alpha=5e-4)\n",
    "    clf.out_activation_ = 'multiclass'\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:\n",
    "        # save the model to disk\n",
    "        filename = 'lbfgs_bc_model_113_100_1000_25_pca.sav'\n",
    "        jb.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "Training: MSE:  0.0  ACC score:  1.0\n",
      "Testing: MSE:  0.008771929824561403  ACC score:  0.9912280701754386\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "loaded_model = jb.load(filename)\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = loaded_model.predict(X_test)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "\n",
    "y_train_pred_load = loaded_model.predict(X_train)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "\n",
    "print('Training: MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print('Testing: MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "\n",
    "embedding = PCA(n_components=20)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")\n",
    "\n",
    "X_sample = len(X_train_bal)\n",
    "X_input = len(X_train_bal[1])\n",
    "X_class = len(np.unique(y_train_bal))\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    print('Training ', i+1, '...')\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(X_input * 3, ), activation='tanh', solver='lbfgs', max_iter=max_iter, alpha=5e-4)\n",
    "    clf.out_activation_ = 'multiclass'\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:\n",
    "        # save the model to disk\n",
    "        filename = 'lbfgs_bc_model_113_100_1000_20_pca.sav'\n",
    "        jb.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "Training: MSE:  0.0  ACC score:  1.0\n",
      "Testing: MSE:  0.017543859649122806  ACC score:  0.9824561403508771\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "loaded_model = jb.load(filename)\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = loaded_model.predict(X_test)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "\n",
    "y_train_pred_load = loaded_model.predict(X_train)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "\n",
    "print('Training: MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print('Testing: MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "\n",
    "embedding = PCA(n_components=15)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")\n",
    "\n",
    "X_sample = len(X_train_bal)\n",
    "X_input = len(X_train_bal[1])\n",
    "X_class = len(np.unique(y_train_bal))\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    print('Training ', i+1, '...')\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(X_input * 3, ), activation='tanh', solver='lbfgs', max_iter=max_iter, alpha=5e-4)\n",
    "    clf.out_activation_ = 'multiclass'\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:\n",
    "        # save the model to disk\n",
    "        filename = 'lbfgs_bc_model_113_100_1000_15_pca.sav'\n",
    "        jb.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "Training: MSE:  0.0  ACC score:  1.0\n",
      "Testing: MSE:  0.008771929824561403  ACC score:  0.9912280701754386\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "loaded_model = jb.load(filename)\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = loaded_model.predict(X_test)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "\n",
    "y_train_pred_load = loaded_model.predict(X_train)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "\n",
    "print('Training: MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print('Testing: MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "\n",
    "embedding = PCA(n_components=10)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")\n",
    "\n",
    "X_sample = len(X_train_bal)\n",
    "X_input = len(X_train_bal[1])\n",
    "X_class = len(np.unique(y_train_bal))\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    print('Training ', i+1, '...')\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(X_input * 3, ), activation='tanh', solver='lbfgs', max_iter=max_iter, alpha=5e-4)\n",
    "    clf.out_activation_ = 'multiclass'\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:\n",
    "        # save the model to disk\n",
    "        filename = 'lbfgs_bc_model_113_100_1000_10_pca.sav'\n",
    "        jb.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "Training: MSE:  0.0  ACC score:  1.0\n",
      "Testing: MSE:  0.02631578947368421  ACC score:  0.9736842105263158\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "loaded_model = jb.load(filename)\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = loaded_model.predict(X_test)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "\n",
    "y_train_pred_load = loaded_model.predict(X_train)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "\n",
    "print('Training: MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print('Testing: MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "scaler = StandardScaler()\n",
    "# Calculate the mean and standard deviation for each variable in the dataset \n",
    "scaler.fit(X_org)\n",
    "# The transformed (scaled) values of X are stored in the variable X_scaled which is also \n",
    "# the same two-dimensional Numpy array.\n",
    "X_scaled = scaler.transform(X_org)\n",
    "\n",
    "embedding = PCA(n_components=5)\n",
    "embedding.fit(X_scaled)\n",
    "X_transformed = embedding.transform(X_scaled)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)\n",
    "\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_org, test_size=0.2, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")\n",
    "\n",
    "X_sample = len(X_train_bal)\n",
    "X_input = len(X_train_bal[1])\n",
    "X_class = len(np.unique(y_train_bal))\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "cost_test = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    print('Training ', i+1, '...')\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(X_input * 3, ), activation='tanh', solver='lbfgs', max_iter=max_iter, alpha=5e-4)\n",
    "    clf.out_activation_ = 'multiclass'\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:\n",
    "        # save the model to disk\n",
    "        filename = 'lbfgs_bc_model_113_100_1000_5_pca.sav'\n",
    "        jb.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "Training: MSE:  0.0  ACC score:  1.0\n",
      "Testing: MSE:  0.0  ACC score:  1.0\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "loaded_model = jb.load(filename)\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = loaded_model.predict(X_test)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "\n",
    "y_train_pred_load = loaded_model.predict(X_train)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "\n",
    "print('Training: MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print('Testing: MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('qpso-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e723b1e260b5828f2d71d426a6cc03faa12a7bd7d58626c9280844c649f5bc24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
