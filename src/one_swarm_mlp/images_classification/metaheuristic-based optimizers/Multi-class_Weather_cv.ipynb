{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4722978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------\n",
    "# import modules\n",
    "#---------------\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib as jb\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import mahotas\n",
    "\n",
    "from os import listdir\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from neuralNetwork.perceptron_qpso import perceptron \n",
    "from neuralNetwork.perceptron_pso import perceptron_pso\n",
    "from neuralNetwork.perceptron_pso_bound import perceptron_pso_bound  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438600ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "#Global variables\n",
    "#----------------\n",
    "\n",
    "root_path = './dataset2/'\n",
    "#train_path = 'seg_train/seg_train/'\n",
    "#test_path = 'seg_test/seg_test/'\n",
    "#pred_path = 'seg_pred/seg_pred/'\n",
    "\n",
    "# Dataset classes: buildings, forest, glacier, mountain, sea, street\n",
    "data_clases = np.array(['cloudy', \n",
    "\t\t\t\t\t\t'rain', \n",
    "\t\t\t\t\t\t'shine', \n",
    "\t\t\t\t\t\t'sunrise'])\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "\n",
    "#---------------------------------\n",
    "# Extract Global features\n",
    "#---------------------------------\n",
    "bins = 4 \n",
    "\n",
    "# feature-descriptor-1: Hu Moments\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature\n",
    "\n",
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(image):\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    # return the result\n",
    "    return haralick\n",
    "\n",
    "# feature-descriptor-3: Color Histogram\n",
    "def fd_histogram(image, mask=None):\n",
    "    # convert the image to HSV color-space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the histogram\n",
    "    return hist.flatten()\n",
    "\n",
    "#---------------------------------\n",
    "# prepare training and testing set\n",
    "#---------------------------------\n",
    "\n",
    "X_train_aux = []\n",
    "y_train_aux = []\n",
    "\n",
    "for c in range(len(data_clases)):\n",
    "\tfor filename in listdir(root_path + data_clases[c] + '/'):\n",
    "\t\t# load image\n",
    "\t\timg_data = cv2.imread(root_path + data_clases[c] + '/' + filename) \n",
    "\t\timg_data = cv2.resize(img_data, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        # Global Feature extraction\n",
    "\t\tfv_hu_moments = fd_hu_moments(img_data)\n",
    "\t\t#print(fv_hu_moments.shape)\n",
    "\t\tfv_haralick = fd_haralick(img_data)\n",
    "\t\t#print(fv_haralick.shape)        \n",
    "\t\tfv_histogram  = fd_histogram(img_data)\n",
    "\t\t#print(fv_histogram.shape)\n",
    "\t\t# Concatenate global features\n",
    "\t\tglobal_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
    "\t\tX_train_aux.append(global_feature)\n",
    "\t\ty_train_aux.append(c)\n",
    "\t\tprint('> loaded %s %s' % (filename, img_data.shape))\n",
    "\t\tprint('> global features %s %s' % (filename, global_feature.shape))\n",
    "\n",
    "# convert to array\n",
    "X_train_aux = np.array(X_train_aux)\n",
    "y_train_aux = np.array(y_train_aux)\n",
    "\n",
    "# normalize data\n",
    "#X_train_aux = X_train_aux / 255\n",
    "\n",
    "print('X_train shape: ', X_train_aux.shape)\n",
    "print('y_train shape: ', y_train_aux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d56b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particulas = 100\n",
    "max_iter = 1000\n",
    "n_training = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13688e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MinMaxScaler()\n",
    "t.fit(X_train_aux)\n",
    "X_train_aux = t.transform(X_train_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bf6d14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train transformed:  (1122, 42)\n"
     ]
    }
   ],
   "source": [
    "embedding = Isomap(n_components=42, n_neighbors=100)\n",
    "X_transformed = embedding.fit_transform(X_train_aux)\n",
    "print ('Shape of X_train transformed: ', X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb406735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({3: 253, 0: 196, 2: 179, 1: 157})\n",
      "Testing target statistics: Counter({0: 104, 3: 104, 2: 72, 1: 57})\n"
     ]
    }
   ],
   "source": [
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_transformed, y_train_aux, test_size=0.3, random_state=100)\n",
    "print(f\"Training target statistics: {Counter(y_train_bal)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test_bal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86acb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = len(X_train_bal)\n",
    "X_input = len(X_train_bal[1])\n",
    "X_class = len(np.unique(y_train_bal))\n",
    "\n",
    "X_train = X_train_bal\n",
    "y_train = y_train_bal\n",
    "X_test = X_test_bal\n",
    "y_test = y_test_bal\n",
    "\n",
    "#---------------------------------------\n",
    "# variable initialize for qpso algorithm\n",
    "#---------------------------------------\n",
    "beta = 1.13 #1.13\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "metric_train = []\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train, beta, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.g_best_value)\n",
    "    metric_train.append(nn.g_best_value_iter)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost:       \n",
    "        np.save(\"mcw_gBest_113_100_1000_42_qdpso.npy\", gBest[i])\n",
    "        np.save(\"mcw_gBestIter_113_100_1000_42_qdpso.npy\", nn.g_best_value_iter)\n",
    "        np.save(\"mcw_avgBest_113_100_1000_42_qdpso.npy\", nn.avg_best_value)\n",
    "        np.save(\"mcw_stdBest_113_100_1000_42_qdpso.npy\", nn.std_best_value)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"Save train metric ....\")\n",
    "np.save(\"mcw_metric_113_100_1000_42_qdpso.npy\", metric_train)\n",
    "print(\"The best training is in iteration: \", cost_test.index(min(cost_test)))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b4b9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "MSE:  0.2789317507418398  ACC score:  0.8724035608308606\n",
      "MSE:  0.05222929936305733  ACC score:  0.9821656050955414\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "model_load = np.load('mcw_gBest_113_100_1000_42_qdpso.npy')\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = np.argmax(nn.forward(X_test, model_load), axis=1)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "print('MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "\n",
    "\n",
    "y_train_pred_load = np.argmax(nn.forward(X_train, model_load), axis=1)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "print('MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cafc58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for pso algorithm\n",
    "#---------------------------------------\n",
    "opt = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "metric_train = []\n",
    "\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron_pso(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train, opt, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.best_cost)\n",
    "    metric_train.append(nn.h_cost)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost: \n",
    "        np.save(\"mcw_gBest_113_100_1000_42_pso.npy\", gBest[i])\n",
    "        np.save(\"mcw_gBestIter_113_100_1000_42_pso.npy\", nn.h_cost)\n",
    "        np.save(\"mcw_avgBest_113_100_1000_42_pso.npy\", nn.avg_best_value)\n",
    "        #np.save(\"pBest_113_100_100_2_42_1.npy\", nn.h_pos)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"Saving train metric .... \")\n",
    "np.save(\"mcw_metric_113_100_1000_42_pso.npy\", metric_train)\n",
    "print(\"The best training is in iteration \", cost_test.index(min(cost_test)))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1219ea6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "MSE:  0.258160237388724  ACC score:  0.8694362017804155\n",
      "MSE:  0.2267515923566879  ACC score:  0.9299363057324841\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "model_load = np.load('mcw_gBest_113_100_1000_42_pso.npy')\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = np.argmax(nn.forward(X_test, model_load), axis=1)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "print('MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "\n",
    "\n",
    "y_train_pred_load = np.argmax(nn.forward(X_train, model_load), axis=1)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "print('MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae87568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# variable initialize for pso algorithm\n",
    "#---------------------------------------\n",
    "opt = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "gBest_value = []\n",
    "gBest = []\n",
    "cost_test = []\n",
    "metric_train = []\n",
    "\n",
    "\n",
    "for i in range(n_training):\n",
    "    # load perceptron\n",
    "    nn = perceptron_pso_bound(X_sample, X_input, X_class)\n",
    "    gBest.append( nn.train(X_train, y_train, opt, n_particulas, max_iter) )\n",
    "    gBest_value.append(nn.best_cost)\n",
    "    metric_train.append(nn.h_cost)\n",
    "    y_test_pred = np.argmax(nn.forward(X_test, gBest[i]), axis=1)\n",
    "    cost_test.append(mean_squared_error(y_test, y_test_pred))\n",
    "    print ('Test prediction cost with training: ', cost_test[i]) \n",
    "    min_cost = min(cost_test)\n",
    "    print (\"Min test prediction cost: \", min_cost)\n",
    "    if  cost_test[i] <= min_cost: \n",
    "        np.save(\"mcw_gBest_113_100_1000_42_pso_bound.npy\", gBest[i])\n",
    "        np.save(\"mcw_gBestIter_113_100_1000_42_pso_bound.npy\", nn.h_cost)\n",
    "        np.save(\"mcw_avgBest_113_100_1000_42_pso_bound.npy\", nn.avg_best_value)\n",
    "        #np.save(\"pBest_113_100_100_2_42_1.npy\", nn.h_pos)\n",
    "        \n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "print(\"Saving train metric .... \")\n",
    "np.save(\"mcw_metric_113_100_1000_42_pso_bound.npy\", metric_train)\n",
    "print(\"The best training is in iteration \", cost_test.index(min(cost_test)))\n",
    "print(\"The golbal best value is: \", gBest_value[cost_test.index(min(cost_test))])\n",
    "print(\"Test prediction cost: \", min(cost_test))\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "971a5077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "=====================================================================\n",
      "MSE:  0.4035608308605341  ACC score:  0.8249258160237388\n",
      "MSE:  0.37070063694267513  ACC score:  0.8624203821656051\n",
      "=====================================================================\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "model_load = np.load('mcw_gBest_113_100_1000_42_pso_bound.npy')\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")\n",
    "y_test_pred_load = np.argmax(nn.forward(X_test, model_load), axis=1)\n",
    "cost_test_load = mean_squared_error(y_test, y_test_pred_load)\n",
    "acc_test_load = accuracy_score(y_test, y_test_pred_load)\n",
    "print('MSE: ', cost_test_load, ' ACC score: ', acc_test_load)\n",
    "\n",
    "\n",
    "y_train_pred_load = np.argmax(nn.forward(X_train, model_load), axis=1)\n",
    "cost_train_load = mean_squared_error(y_train, y_train_pred_load)\n",
    "acc_train_load = accuracy_score(y_train, y_train_pred_load)\n",
    "print('MSE: ', cost_train_load, ' ACC score: ', acc_train_load)\n",
    "print(\"=====================================================================\")\n",
    "print(\"=====================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('qpso-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e723b1e260b5828f2d71d426a6cc03faa12a7bd7d58626c9280844c649f5bc24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
